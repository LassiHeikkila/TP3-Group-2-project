%group_report.tex

%specify class of document
\documentclass[12pt, a4paper]{article}

%specify packages used 
\usepackage{microtype}		       %use package for minor typographical adjustments
\usepackage{graphicx} 		       %use package for diagram 
\usepackage{listings}                  %use package for c++ code in appendix
\usepackage{color}                     %use package for code listings
\usepackage[utf8]{inputenc}            %use package for colours in code
\usepackage{amsmath}                   %use package for various math symbols
\usepackage{amsfonts}                  %use package for number sets
\usepackage{bm}			       %use package for bolds in math mode
\usepackage{hyperref}                  %use package for hyperlinks
\usepackage{algpseudocode}             %use package for pseudocode
\usepackage{algorithm}                 %use package for pseudocode
\usepackage{fullpage}                  %use package for full page size
\usepackage{tikz}		       %use package for diagram drawings
\usepackage{caption}		       %use package for multiple figures
\usepackage{subcaption}                %use package for multiple figures
\usepackage{tabularx}		       %use package for tables
\usepackage{array}                     %use package for centering table contents
%\usepackage{url}                       %use package to display urls properly

%set graphics path
\graphicspath{{/home/danmfr/p3t/laplace/images/}}

%define colours for code listings
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

%define a style for the listings
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

%set style of listing to that defined above
\lstset{style=mystyle}

%use tikz library for shapes
\usetikzlibrary{shapes.geometric, arrows}

%define block styles in tikz
\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=red!30]
\tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=blue!30]
\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=orange!30]
\tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]
\tikzstyle{arrow} = [thick,->,>=stealth]

%set style of bibliography
\bibliographystyle{unsrt}

%set style of footnotes
\renewcommand{\thefootnote}{\roman{footnote}}

%define command shortcuts
\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}

%redefine columns for tabularx
\newcolumntype{Y}{>{\centering \arraybackslash}X}

\begin{document}

\title{On numerical approximations to solutions of Laplace's equation for different
electrostatic configurations}
\author{S. Brown, F. Hayes, L. Heikkil{\"a}, D. Richardson,\\
	School of Physics and Astronomy,\\
	University of Glasgow,\\
	Glasgow, United Kingdom}
\date{\today}
\maketitle

\begin{abstract}

The behaviour of the electric field under the presence and influence of solid
conducting objects is modelled and studied. Finite difference methods, namely
relaxation methods, are employed to solve the Laplace equation numerically,
to find the approximate form of the electrostatic potential, and hence the electric
field, present in various electrostatic systems.

We explicitly focus on two such systems: first, the case of a long perfectly conducting
cylinder centred between two infinite planes at potential $+V$ and $-V$; and secondly 
the case of a silicon detector---a system composed of two silicon wafers with segmented
doped implants at ground potential on one side and a uniform doped implant on the
other side, held at a potential $+V$. We present the analytical solution of the first
system. We then compare this solution to the approximate numerical solution produced
by five different relaxation methods, and examine the relative error and relative
convergence of each of them. We then conclude that the method of 
\emph{Checkerboard Updating with successive over-relaxation} is best.

We then discuss the design, implementation and operation of a software package we have
developed, \emph{estatics}, which is capable of solving Laplace's equation for arbitrary
constant boundary conditions, using the chosen relaxation method. We then present the
output of the package for different electrostatic systems, and propose opportunities
for further work.

\end{abstract}

% DO NOT INCLUDE IN FINAL VERSION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage                       %
\tableofcontents               %
\newpage                       %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\subsection{Laplace's Equation}

The Laplace equation, named after mathematician and physicist Pierre-Simon de Laplace,
is a linear second-order partial differential equation that can be used to describe
steady-state distributions of heat, fluids and potential. It states that the divergence
of the gradient of a function, $\phi$ say, is zero. Symbolically:
%
\be
\nabla ^2 \phi = 0
\ee
%
where $\nabla^2$ is called the \emph{Laplacian operator}. The study of solutions to
this equation is known as \emph{potential theory}.

The exact form of the equation is dependent upon the co-ordinate system in which one
considers it. In two dimensions, where subscripts denote partial differentiation with
respect to that variable:

\begin{center}
\begin{tabularx}{0.6\textwidth}{|Y|Y|}
\hline
\emph{Cartesian co-ordinates} & \emph{Polar co-ordinates} \\
$\phi_{xx}+\phi_{yy}=0$ & $\phi_{rr}+\frac{1}{r}\phi_r+\frac{1}{r^2}\phi_{\theta \theta}=0$ \\
\hline
\end{tabularx}
\end{center}

The Laplace equation shall now be derived in the context of electromagnetism.

\subsubsection{Derivation of Laplace equation in Electomagentism}
We begin by considering the two Maxwell equations that describe the electric field,
\textbf{E}.

Gauss' Law may used to express the relation between the \emph{divergence} of the
electric field, and the \emph{charge density} $\rho$,
%
\be
\nabla \cdot \bm{E} = \frac{\rho}{\epsilon_0}
\ee
%
where $\epsilon_0$ is the \emph{permittivity of free space}. Alternatively (c.f.
\emph{the Divergence Theorem}), it can be expressed in its integral form, as:
%
\be
\oint \limits_S \bm{E} \cdot d\bm{A} = \frac{Q}{\epsilon_0}
\ee
%
where the integral is taken over a closed surface, $S$, and $Q$ is the enclosed charge.
In the absence of charge, as is the case in free space outside a conductor, this
reduces to the statement that the electric field is \emph{solenoidal}
($\nabla \cdot \bm{E}=0$).

One can also relate the \emph{curl} of the electric field to the time
derivative of the magnetic field, denoted \textbf{B}, by the Maxwell-Faraday equation:
%
\be
\nabla \times \bm{E} = - \frac{\partial \bm{B}}{\partial t}
\ee

If the magnetic field is constant, this equation reduces to the statement that
the electric field is \emph{irrotational} ($\nabla \times \bm{E}=0$). A
consequence of irrotationality is that the electric field may then be written as
the gradient of some scalar potential, $\phi$ say. Mathematically:
%
\be
\bm{E} = -\nabla \phi
\ee
%
where the negative sign is convention. This scalar potential is called the
\emph{electrostatic potential}.

One then has \emph{Laplace's equation}:
%
\be
\nabla^2 \phi = 0
\ee

This is a linear second-order partial differential equation that can be solved, given
some well-posed boundary conditions, to find the electrostatic potential and hence
electric field for some physical system. This, in turn, can be used to find the
equations of motion of test particles within the system, via the Lorentz force law.

The following analysis occurs in the context of electromagnetism but is easily
generalised to other areas of physics were the Laplace equation occurs, for example,
fluid dynamics, heat conduction and astronomy.

\subsection{Description of Physical Systems}

Suppose one has a perfectly uniform electric field between two infinite planes
at potentials $V$ and $-V$, and they are a distance $2d$ apart. Suppose one then
places an infinitely long perfectly conducting cylinder, of radius $R$, into the centre
of the field, at ground potential, as in Figure~\ref{fig:sys one}. We wish to find the
resulting form of the electrostatic potential, and hence the electric field, surrounding
the cylinder.

\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}
\draw (0,0) node[below] {$x = -d$} -- (0,4.8) node[above] {$\phi = V$}; 
\draw (8,0) node[below] {$x = d$} -- (8,4.8) node[above] {$\phi = -V$}; 
\draw (4,2.4) circle (1cm) node[below] {$\phi=0$};
\draw[dashed] (4,2.4) -- (4.6,3.2) node[pos=0.5,above left] {$R$};
\end{tikzpicture}
\end{center}
\caption{Cross-sectional diagram of System One}
\label{fig:sys one}
\end{figure}

The second system considered was a silicon detector---a system consisting of two
silicon wafers, one segmented with doped implants at ground potential and the other,
referred to as the backplane, uniformly doped, held at a potential $+V$, as shown
in Figure~\ref{fig:sys two}.

\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}
\draw (0,0) -- (9.6,0) node[right] {$\phi = V$}; 
\draw (0,4) -- (9.6,4) node[pos=0.25, above, font=\footnotesize] {GND} node[pos=0.5, above, font=\footnotesize] {GND} node[pos=0.75,above, font=\footnotesize] {GND}; 
\draw (2,4) rectangle (2.8,3.8);
\draw (4.4,4) rectangle (5.2,3.8);
\draw (6.8,4) rectangle (7.6,3.8);
\end{tikzpicture}
\end{center}
\caption{Cross-sectional diagram of System Two}
\label{fig:sys two}
\end{figure}

System One can be solved analytically, as will be shown in the subsequent section. We
shall use this solution to compare the accuracy of different numerical methods in solving
System One, and decide which method is best suited to solve more complex systems, such
as System Two, that do not have analytical solutions.

\subsection{Analytical Solution of System One}

First, one realises that the three-dimensional problem can be reduced entirely to two
dimensions due to the translation symmetry of the system along the length of the
cylinder. So, we consider a cross-section of the system and introduce a polar
co-ordinate system, with origin centred on the centre of the cylinder, as this permits
one to exploit the rotational symmetry of the system.

Laplace's equation in plane polar co-ordinates is: 
%
\be
\frac{\partial^2 \phi}{\partial r^2}+\frac{1}{r}\frac{\partial \phi}{\partial r}+\frac{1}{r^2}\frac{\partial^2 \phi}{\partial \theta^2}
= \frac{1}{r}\frac{\partial}{\partial r}(r \frac{\partial \phi}{\partial r}) + \frac{1}{r^2}\frac{\partial ^2 \phi}{\partial \theta^2}
= 0
\ee

We employ separation of variables and posit a solution of the form
$\phi = f(r)g(\theta)$ for two unknown functions $f$ and $g$. Upon substitution,
one finds that:
%
\be
\frac{r}{f(r)}\frac{d}{dr}(r \frac{df(r)}{dr}) =- \frac{1}{g(\theta)}\frac{d^2 g(\theta)}{d\theta^2}
\ee

Since the left-hand side is solely a function of $r$---and the right-hand side of
$\theta$---they both must be constant if the relation is to hold for arbitrary values
of $r$ and $\theta$. Then---with some foreknowledge---one sets this constant equal to
$k^2$, for some constant $k\in\mathbb{R}$. This gives two second-order ordinary
differential equations:
%
\be
r\frac{d}{dr}(r \frac{df(r)}{dr}) = k^2 f(r) \qquad
\frac{d^2 g(\theta)}{d\theta^2}=-k^2 g(\theta)
\ee

For the case $k=0$, these equations have solutions
$f(r)=\alpha \ln(r) + \beta$ and $g(\theta) = \gamma \theta + \delta$.
For non-zero $k$, they have solutions
%
\be
f(r)=\alpha_k r^k + \beta_k r^{-k}
\qquad
g(\theta)= \gamma_k \sin(k\theta)+\delta_k \cos(k\theta)
\ee

For consistency, we expect $g$ to be single-valued and periodic, namely that
$g(\theta)=g(\theta + 2\pi)$, so that $k$ can only take integer values. Hence, by
the principle of superposition and the linearity of the Laplace equation, its general
solution in polar co-ordinates is a sum of such terms:
%
\be
\phi(r,\theta)
= f(r)g(\theta)
= (\alpha \ln(r) + \beta)(\gamma\theta + \delta) + \sum_{n=1}^{\infty}(\alpha_n r^n+\beta_n r^{-n})(\gamma_n \sin(n\theta) + \delta_n \cos(n\theta))
\ee

For a particular solution to the system considered here one must impose boundary
conditions. Specifically, we use \emph{Dirichlet boundary conditions}, where the value
of the solution at each boundary is specified. One could also use
\emph{Von Neumann boundary conditions} where the derivative at each boundary is
specified. 

By considering the geometry of the system, we expect a solution that is symmetric
about $\theta=0$. This directly implies that $\gamma = 0$ and $\gamma_n=0$, $\forall n$
as $\sin(\theta)$ and $\theta$ are both anti-symmetric (or odd) about the origin.
Additionally, the potential is finite as $r \rightarrow \infty$, which implies that
$\alpha$ and $\alpha_n$ are both zero. We now have:
%
\be
\phi(r,\theta)=\beta + \sum_{n=1}^{\infty}(\frac{\beta_n}{r^n} \cos(n\theta))
\ee
%
where the $\beta$'s have absorbed other constants. In particular, as
$r \rightarrow \infty$, that is as the influence of the cylinder becomes negligible,
we expect the potential to be linearly decreasing between the plates. Mathematically,
we require $\phi=-\frac{V}{d}x=-\frac{V}{d}r\cos(\theta)$ in polar co-ordinates.
Since the infinite sum vanishes at infinity, we have that
$\beta=-\frac{V}{d}r\cos(\theta)$.

We now have that
%
\be
\phi(r,\theta)=-\frac{V}{d}r\cos(\theta) + \sum_{n=1}^{\infty}(\frac{\beta_n}{r^n} \cos(n\theta))
              =(\frac{\beta_1}{r}-\frac{V}{d}r)\cos(\theta) + \sum_{n=2}^{\infty}(\frac{\beta_n}{r^n} \cos(n\theta))
\ee

We expect continuity of the potential at the surface of the cylinder:
$\phi(r=R,\theta)=0$, so that $\beta_1=\frac{VR^2}{d}$ and $\beta_{n \geq 2}=0$,
since the set $\{\cos(n\theta)\}$ are linearly independent functions.

Thus, the final form for the electrostatic potential for System One (see
Figure~\ref{fig:analytic}) is
%
\be
\phi(r,\theta)=
\begin{cases} \quad \qquad 0, & \quad r \leq a \\
\frac{V}{d}(\frac{R^2}{r}-r)\cos(\theta), & \quad r > a
\end{cases}
\ee

\begin{figure}
\begin{center}
\includegraphics{analytic.pdf}
\caption{Analytical solution for the electrostatic potential of System One, with $V=1$,
$R=15$, $d=50$}
\label{fig:analytic}
\end{center}
\end{figure}

\section{Numerical Methods}
\subsection{Finite Difference Methods}

System One is a very idealised system that is not practically reasonable, for example
charged planes that are infinite in extent do not exist. For real-world systems
it is difficult, and often impossible, to express boundary conditions in a manner that
is algebraically utilisable and is thus impossible to find a particular analytical
solution to Laplace's equation for arbitrary, non-trivial, boundary conditions. Solutions
for these systems must be numerically approximated.

To numerically approximate the solution to a differential equation it is
necessary to approximate the derivative of a function. The usual method employed to
do this is finite differencing. This approximates the derivative by using explicit
differencing to step the function from one value to the next in small 
increments of some variable. The smaller the increment used, the more accurate
the approximation, but the longer and more computationally intensive the process.

Suppose one wishes to approximate the first derivative of a function $f(t)$, say,
with respect to the variable $t$. The simplest way to do this is to discretise the
definition of the derivative and write
%
\be
\frac{df}{dt} = \lim_{\Delta t \to 0} \frac{f(t+\Delta t) - f(t)}{\Delta t} \approx \frac{f(t+\Delta t) - f(t)}{\Delta t}
\ee
%
where $f(t+\Delta t)$ and $f(t)$ are two values of $f$, evaluated at two points
a distance $\Delta t$ apart, and $\Delta t$ is assumed to be small enough that
the approximation is good. This is known as the \emph{forward difference approximation}.

Similarly, to approximate the second derivative of a function, one writes
%
\be
\frac{d^2 f}{dt^2} \approx \frac{f'(t) - f'(t-h)}{\Delta t} \\
= \frac{\frac{f(t +\Delta t) - f(t)}{\Delta t} - \frac{f(t) - f(t -\Delta t)}{\Delta t}}{\Delta t} \\
= \frac{f(t +\Delta t) - 2f(t) + f(t-\Delta t)}{\Delta t ^2}
\ee

\subsection{Discretisation of Laplace's Equation}

To numerically solve the Laplace equation it must be expressed in a discrete form.
We define a rectangular region on which to discretise Laplace's equation, given by:
%
\be
\{(x,y)|\:0<x<a, 0<y<b\}
\ee
%
and create a grid of points at which to evaluate the potential of spacial separation
$\Delta x$ in the $x$ direction, and $\Delta y$ in the $y$ direction (see
Figure~\ref{fig:grid}).

\begin{figure}
\centering
\begin{tikzpicture}

\foreach \x in {0,...,10}
{
\draw[fill=black] (0.5*\x,0) circle (0.1cm);
\draw[fill=black] (0.5*\x,5) circle (0.1cm);
}

\foreach \y in {0,...,10}
{
\draw[fill=black] (0,0.5*\y) circle (0.1cm);
\draw[fill=black] (5,0.5*\y) circle (0.1cm);
}

\foreach \x in {1,...,9}
\foreach \y in {1,...,9}
{
\draw[fill=white] (0.5*\x,0.5*\y) circle (0.1cm);
}
\fill (0,0) node[below left, font=\footnotesize] {$(x_0,y_0)$};
\fill (2.5,0) node[below, font=\footnotesize, yshift = -0.2cm] {$x_j=j\Delta x$};
\fill (5,2.5) node[right, font=\footnotesize, xshift = 0.2cm] {$y_k=k\Delta y$};
\end{tikzpicture}
\caption{A pictorial representation of the grid on which the potential is approximated.
White points denote interior points that change value; black points denote constant
boundary points at which Dirichlet boundary conditions are imposed.}
\label{fig:grid}
\end{figure}

For simplicity, the Laplace equation in two-dimensional Cartesian co-ordinates is
discretised:
% 
\be 
\frac{\partial^2 \phi}{\partial x^2}+\frac{\partial^2 \phi}{\partial y^2} = 0
\label{eq:laplace}
\ee 

Writing the value of the potential at position $(x_j,y_k)$ on the grid as $\phi_{j,k}$,
one can now approximate Eqn.~\ref{eq:laplace} as:
% 
\be
\frac{\phi_{j+1,k}-2\phi_{j,k}+\phi_{j-1,k}}{\Delta x^2} = - \frac{\phi_{j,k+1}-2\phi_{j,k}+\phi_{j,k-1}}{\Delta y^2}
\ee
%
where $j$ and $k$ index the $x$ and $y$ directions respectively.

For a unique spacing $\Delta=\Delta x=\Delta y$ in both $x$ and $y$ directions this
reduces to the statement that the value of the potential at a specific point is the
average of the value of the potential at the four surrounding points: 
%
\be
\phi_{j,k}= \frac{1}{4}(\phi_{j-1,k}+\phi_{j+1,k}+\phi_{j,k-1}+\phi_{j,k+1})
\label{eq:relax}
\ee

\subsection{Jacobi's Iterative Method}

Suppose one has some initial guess of the value of the potential at all points on the
grid, $\phi_{j,k,0}$, say. One evaluates Eqn~\ref{eq:relax} at all points on the grid
simultaneously and generates a new better approximation for the potential,
$\phi_{j,k,1}$. Iterating this process $n$ times, one has
%
\be
\phi_{j,k,n+1}= \frac{1}{4}(\phi_{j-1,k,n}+\phi_{j+1,k,n}+\phi_{j,k-1,n}+\phi_{j,k+1,n})
\ee
%
This is known as \emph{Jacobi's iterative method}, the simplest version of a
\emph{relaxation method}, an algorithm where the numerical approximation converges or
\emph{relaxes} towards the analytical solution with increasing iterations. 

\subsection{The Gauss-Seidel Method}

As the grid is iterated through and relaxation is applied, points at which the potential
has already been updated---namely $\phi_{j-1,k}$ and $\phi_{j,k-1}$ in our notation---are
presumably more accurate to the correct solution than points that have not been updated.
An alternative relaxation method, known as the \emph{Gauss-Seidel method}, takes use of
this supposition and defines an iterative scheme given by:
%
\be
\phi_{j,k,n+1}= \frac{1}{4}(\phi_{j-1,k,n+1}+\phi_{j+1,k,n}+\phi_{j,k-1,n+1}+\phi_{j,k+1,n})
\ee

It can be shown that this method converges faster than Jacobi's iterative
method, and it also has the added bonus of not requiring the previous value of the 
potential at each grid point to be stored, thus reducing computation time.

\subsection{Successive Over-Relaxation}

Neither the Jacobi iterative method nor the Gauss-Seidel method utilise the value
of the potential at the current point in the previous iteration, in our notation
$\phi_{j,k,n}$. It can be shown that using this point, and defining a
\emph{relaxation parameter}, $1<s<2$, one can define the following iterative algorithm:
%
\be
\phi_{j,k,n+1}= (1-s)\phi_{j,k,n}+\frac{s}{4}(\phi_{j-1,k,n+1}+\phi_{j+1,k,n}+\phi_{j,k-1,n+1}+\phi_{j,k+1,n})
\ee
%
where the optimum value for $s$ for an $n \times n$ square grid is
\be
s_{opt} = \frac{2}{1+\sin(\frac{\pi}{n})} \approx \frac{2}{1+\frac{\pi}{n}}
\ee

This is a more convergent numerical method than those previously and is called 
\emph{successive over-relaxation}.

%add fergus
%\input{sor.tex}

\subsection{Checkerboard (Red-Black) Updating}

In each of the previous methods, the value of the potential is calculated from, at most,
its previous value at the current point and the current or previous values of the
potential at the four neighbouring points. Noting this, let us denote $\phi_{j,k}$ as
\emph{odd} if $j+k$ is odd, and even otherwise. Then the potential at each even point
solely depends on the potential at odd points, and vice-versa. One could then, in
principle, iterate through the grid of points at which the potential is approximated,
and update all the odd points, and then re-iterate through the grid, updating all the
even points using the value of the potential at the newly updated odd points. Such an
iterative scheme exists, and is known as \emph{Checkerboard (Red-Black) Updating}. The
method essentially reduces a system of $N$ linear equations into two coupled systems
of $\frac{N}{2}$ linear equations that can be solved separately.

The method can be shown to be a more convergent method than those outlined previously,
and successive over-relaxation can easily be implemented within the scheme.
Figure~\ref{fig:checker} shows an illustration of the algorithm.

\begin{figure}[h!]
\begin{center}
	\begin{tikzpicture}
	\draw[fill=red] (0,0) circle (0.2cm) node[below] {$\phi_{j+1,k-1,n}$}; 
	\draw[fill=black] (2,0) circle (0.2cm) node[below] {$\phi_{j+1,k,n}$}; 
	\draw[fill=red] (4,0) circle (0.2cm) node[below] {$\phi_{j+1,k+1,n}$};
	\draw[fill=black] (0,2) circle (0.2cm) node[below] {$\phi_{j,k-1,n}$};
	\draw[fill=red] (2,2) circle (0.2cm) node[below] {$\phi_{j,k,n}$};
	\draw[fill=black] (4,2) circle (0.2cm) node[below] {$\phi_{j,k+1,n}$};
	\draw[fill=red] (0,4) circle (0.2cm) node[below] {$\phi_{j-1,k-1,n}$};
	\draw[fill=black] (2,4) circle (0.2cm) node[below] {$\phi_{j-1,k,n}$};
	\draw[fill=red] (4,4) circle (0.2cm) node[below] {$\phi_{j-1,k+1,n}$};
	\end{tikzpicture}
\end{center}
\caption{An illustration of checkerboard updating. The black points are updated first,
and then red points are updated using the newly updated black points.}
\label{fig:checker}
\end{figure}

Another advantage of this method is that due to the independent nature of the red and
black points, it lends itself particularly well to the introduction of parallel 
computing, which can reduce computation time even more, particularly for larger grid
sizes.

%add stephen
%\input{checker.tex}

\subsection{Nine-point Stenciling}
\input{nine_p.tex}

\subsection{Comparison of methods}

To decide which relaxation method was best to implement in the software package,
each method was coded into C++ and ran to solve Laplace's equation for System One.
The resulting numerical approximations can be seen in Figure~\ref{fig:comparison}.

%fig:comparison

As there is very little graphical difference between each method, more quantitative
comparison methods were emplyed, namely the relative convergence and error---as
compared to the analytical solution---of each method, and their dependence on number
of iterations, was studied. The CPU time for each method was also studied. The results
are summarised in Figure~\ref{fig:stats}.

\begin{figure}
\centering
\begin{subfigure}{0.8\textwidth}
	\includegraphics[scale=0.8]{rel_convergence.pdf}
	\caption{Average relative convergence, between successive approximations for the potential of each method, versus number of iterations}
	\label{fig:conv}
\end{subfigure}

\begin{subfigure}{0.8\textwidth}
	\includegraphics[scale=0.8]{rel_error.pdf}
	\caption{Average relative error of each method, as compared to the analytical solution, versus number of iterations}
	\label{fig:err}
\end{subfigure}

\begin{subfigure}{0.8\textwidth}
	\includegraphics[scale=0.8]{time.pdf}
	\caption{CPU time taken by each method versus number of iterations}
	\label{fig:time}
\end{subfigure}
\caption{Summary of the method comparison statistics}
\label{fig:stats}
\end{figure}

The following conclusions were drawn from the data:
%
\begin{itemize}
\item the addition of successive over-relaxation causes drastic increase in convergence;
\item average relative error essentially converges for all methods;
\item CPU time is not an important factor.
\end{itemize}

%maybe include plot of completion time vs desired convergence

Hence, Checkerboard Updating with successive over-relaxation was chosen to be used
in the genereal software package, since it converges in the least iterations,
and hence least time, but to the same accuracy as the other methods.

\section{Software Package \emph{estatics} for general electrostatic systems}

A general software package in C++ was developed to solve and plot the potential and
electric field for an arbitrary electrostatic system. It accepts input of a coloured
bitmap, where the colours represent different constant potentials, converts this into
an array of values and applies checkerboard updating with successive over-relaxation
to this array until each grid point is deemed to have converged. The package then
returns plots of the resultant electrostatic potential, equipotential lines and electric
field.

Appendix~\ref{app:flowchart} shows a flowchart of the software.

\subsection{Bitmaps}
\input{bitmap.tex}

\subsection{Data Handling}
%\input{data.tex}

\subsection{Convergence}
\input{convergence.tex}

\subsection{Boolean Masks and Locking}
%\input{boolean.tex}

\subsection{Timing and CPU usage}

\subsection{Parallel Processing}
%\input{parallel.tex}

\subsection{Output and Plotting}
\input{plotting.tex}

\section{Results}
%\input{results.tex}

\section{Conclusion}

\subsection{Further Work}
Fast Fourier transforms

Time-varying potentials

Multigrid methods.

Poisson's equation ($\rho \neq 0$).

Time evolution i.e. time dependency (heat equation).

%include BibTex bibliography
\bibliography{report}

%start of appendix
\appendix
\section{Appendices}
\subsection{Algorithm for System One}
To numerically approximate the electrostatic potential for System 1 via the 
relaxation method the following rudimentary algorithm was developed.

\begin{algorithm}
\begin{algorithmic}[1]
\Procedure{The Relaxation Method}{}
\State declare variables:
\State $V \gets$ potential on plates
\State $\delta \gets$ position step-size
\State $d \gets$ distance between plates
\State $h \gets$ height of plates
\State $r \gets$ radius of cylinder
\State $its \gets$ number of iterations
\State $nx \gets \frac{d}{\delta}$ 
\State $ny \gets \frac{h}{\delta}$ 
\State specify boundary potentials:
\For {$j=1$ to $ny$}
   \State $u_{j, 1} = +V$
   \State $u_{j, nx} = -V$
\EndFor
\For {$k=1$ to $nx$}
   \State $u_{1, k} \gets V-\frac{2Vj}{nx}$
   \State $u_{ny, k} \gets V-\frac{2Vj}{nx}$
\EndFor
\State find solution:
\For {$i=1$ to $its$}
   \For {$j=2$ to $ny-1$}
      \For {$k=2$ to $nx-1$}
         \If {$(j \delta-\frac{1}{2} d)^2+(k \delta-\frac{1}{2} h)^2<r^2$}
            \State $u_{j, k} \gets 0$
         \Else
            \State $u_{j,k} \gets \frac{1}{4}(u_{j-1,k}+u_{j+1,k}+u_{j,k-1}+u_{j,k+1})$
         \EndIf
      \EndFor
   \EndFor
\EndFor
\State find electric field:
\For {$j=1$ to $ny-1$}
   \For {$k=1$ to $nx-1$}
      \State $(Ex)_{j, k} \gets -\left(u_{j,k+1}-u_{j,k}\right)/\delta$
      \State $(Ey)_{j,k} \gets -\left(u_{j+1,1}-u_{j,k}\right)/\delta$
   \EndFor
\EndFor
\State plot potential and field
\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{Flowchart for System}
\label{app:flowchart}
\begin{figure}[htbp!]
\begin{center}
\begin{tikzpicture}[node distance=1.8cm]

\node (start) [startstop] {start};
\node (in1) [io, below of=start] {input of bitmap and potentials};
\node (pro1) [process, below of=in1] {convert bitmap to matrix};
\node (pro2) [process, below of=pro1] {apply relaxation to matrix};
\node (dec1) [decision, below of=pro2, yshift=-1.5cm] {check convergence};
\node (inv) [inner sep=0, minimum size=0, right of=dec1, xshift=2cm] {}; % invisible node
\node (pro3) [process, below of=dec1, yshift=-1.5cm] {find electric field};
\node (out1) [io, below of=pro3] {plot field and potential};
\node (stop) [startstop, below of=out1] {stop};

\draw [arrow] (start) -- (in1);
\draw [arrow] (in1) -- (pro1);
\draw [arrow] (pro1) -- (pro2);
\draw [arrow] (pro2) -- (dec1);
\draw [arrow] (dec1) -- node[left] {convergent} (pro3);
\draw (dec1) -- (inv);
\draw [arrow] (inv) |- node[pos=0.25, right] {non-convergent} (pro2);
\draw [arrow] (pro3) -- (out1);
\draw [arrow] (out1) -- (stop);

\end{tikzpicture}
\end{center}
\caption{Flowchart of steps in software package}
\label{fig:flowchart}
\end{figure}

\end{document}
