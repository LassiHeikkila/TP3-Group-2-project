\section{Convergence and Relative Error}
\subsection{Convergence}
The successive over relaxation method does not have an easily quantifiable error. The truncation error associated with each iteration requires numerically calculating larger derivatives of the functions which require as much computational work, if not more, than finding the solutions needs. Instead the precision of our results are analysed.
\\
The precision is related to how close a numerically determined value is from the true value it is converging to. If a numerical process determines a value $\tilde{x}$ on iteration $n$ which is converging to $x$, then:
\begin{align}
\lim_{n \rightarrow \infty}\tilde{x} = x                     
\end{align}
As the true value $x$ is constant, if the expression is differentiated with respect to the number of iterations, the rate of change of the determined value $\tilde{x}$ over iterations tends towards zero:
\begin{align}
\lim_{n \rightarrow \infty}\frac{d\tilde{x}}{dn} = \lim_{n \rightarrow \infty} (\tilde{x}^{n} - \tilde{x}^{n-1}) = 0                     
\end{align}
The magnitude of the difference of determined values $\tilde{x}$ between successive iterations is then related to how close the value is to the true value $x$. The closer the value is to zero, the more precise the value.
\subsection{Relative Error}
The magnitude of the difference of the potential between successive iterations at some point is referred to as relative error $\epsilon_{rel}$ of that point:
\begin{align}
\epsilon_{rel \; i,j}^{n} = |\tilde{\phi}^{n} - \tilde{\phi}^{n-1}|
\end{align}
This value is used in the program to limit the number of iterations the numerical process undertakes and also is used to 'lock' converged points to reduce calculations per iteration.
